# PyTorch

This is a simple tutorial to provide an understanding of what is PyTorch and what it is useful for.

## Introduction

PyTorch is defined as an open source machine learning library for Python. It is initially developed by Facebook artificial-intelligence research group, and Uber’s Pyro software for probabilistic programming which is built on it.

Originally developed by Hugh Perkins as a Python wrapper based on Torch framework, PyTorch is very "pythonic", meaning it will feel more natural to use if you are already familiar with Python programming.

PyTorch redesigns and implements Torch in Python while sharing the same core C libraries for the backend code. PyTorch developers tuned this back-end code to run Python efficiently. They also kept the GPU based hardware acceleration as well as the extensibility features that made Lua-based Torch.

## Features

### Easy Interface
- PyTorch offers easy to use API hence it is considered to be very simple to operate and runs on Python. The code execution in this framework is quite easy

### Python usage
- This library is considered to be Pythonic which smoothly integrates with the Python data science stack. Thus, it can leverage all the services and functionalities offered by the Python environment.

### Computational graphs 
- PyTorch provides an excellent platform which offers dynamic computational graphs. Thus a user can change them during runtime. This is highly useful when a developer has no idea of how much memory is required for creating a neural network model.

PyTorch is known for having three levels of abstraction as given below −

-- Tensor − Imperative n-dimensional array which runs on GPU.

-- Variable − Node in computational graph. This stores data and gradient.

-- Module − Neural network layer which will store state or learnable weights.
